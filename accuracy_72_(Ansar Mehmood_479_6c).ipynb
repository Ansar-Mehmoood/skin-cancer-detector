{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# prompt: Skin cancer is my disease. there is a folder named Dataset in my drive. then there are two folders in it named benign and malignant. Train my model for the images in these folders that should predict skin cancer. fine tune the model. The accuracy should be at least 80\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import os\n",
        "\n",
        "# Define image dimensions and batch size'\n",
        "img_width, img_height = 150, 150\n",
        "batch_size = 32\n",
        "\n",
        "# Define data directories\n",
        "dataset_dir = '/content/drive/MyDrive/melanoma_cancer_dataset'  # Update with your actual path\n",
        "benign_dir = os.path.join(dataset_dir, 'benign')\n",
        "malignant_dir = os.path.join(dataset_dir, 'malignant')\n",
        "\n",
        "# Data augmentation and preprocessing\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    validation_split=0.2  # 20% for validation\n",
        ")\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    dataset_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary',  # Assuming binary classification (benign/malignant)\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "    dataset_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary',\n",
        "    subset='validation'\n",
        ")\n",
        "\n",
        "# Build a CNN model (example architecture)\n",
        "model = keras.Sequential([\n",
        "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(img_width, img_height, 3)),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dense(1, activation='sigmoid')  # Output layer for binary classification\n",
        "])\n",
        "\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "epochs = 20  # Adjust the number of epochs as needed\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_generator.samples // batch_size,\n",
        "    epochs=epochs,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=validation_generator.samples // batch_size\n",
        ")\n",
        "\n",
        "# Fine-tune (optional): Unfreeze some layers and retrain with a lower learning rate\n",
        "# ...\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(validation_generator)\n",
        "print(f\"Validation Accuracy: {accuracy*100:.2f}%\")\n",
        "\n",
        "# Save the model (optional)\n",
        "# model.save(\"skin_cancer_model.h5\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QA2RhpIsSmXD",
        "outputId": "6e6f8539-542f-4e3f-9cc6-87f5699956dc"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 8579 images belonging to 3 classes.\n",
            "Found 2143 images belonging to 3 classes.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3332s\u001b[0m 12s/step - accuracy: 0.7158 - loss: -13227117.0000 - val_accuracy: 0.7216 - val_loss: -932947392.0000\n",
            "Epoch 2/20\n",
            "\u001b[1m  1/268\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5:57\u001b[0m 1s/step - accuracy: 0.6875 - loss: -1402944768.0000"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/epoch_iterator.py:107: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self._interrupted_warning()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 258ms/step - accuracy: 0.6875 - loss: -1402944768.0000 - val_accuracy: 0.7202 - val_loss: -957695872.0000\n",
            "Epoch 3/20\n",
            "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m562s\u001b[0m 2s/step - accuracy: 0.7210 - loss: -3228873728.0000 - val_accuracy: 0.7216 - val_loss: -35529637888.0000\n",
            "Epoch 4/20\n",
            "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 161ms/step - accuracy: 0.6250 - loss: -38757842944.0000 - val_accuracy: 0.7206 - val_loss: -35940818944.0000\n",
            "Epoch 5/20\n",
            "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m502s\u001b[0m 2s/step - accuracy: 0.7152 - loss: -60945793024.0000 - val_accuracy: 0.7202 - val_loss: -319132794880.0000\n",
            "Epoch 6/20\n",
            "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 158ms/step - accuracy: 0.6875 - loss: -671429689344.0000 - val_accuracy: 0.7230 - val_loss: -319193776128.0000\n",
            "Epoch 7/20\n",
            "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m502s\u001b[0m 2s/step - accuracy: 0.7315 - loss: -383265800192.0000 - val_accuracy: 0.7206 - val_loss: -1561215500288.0000\n",
            "Epoch 8/20\n",
            "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 162ms/step - accuracy: 0.8438 - loss: 356678074368.0000 - val_accuracy: 0.7211 - val_loss: -1545591848960.0000\n",
            "Epoch 9/20\n",
            "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m501s\u001b[0m 2s/step - accuracy: 0.7160 - loss: -1646247149568.0000 - val_accuracy: 0.7221 - val_loss: -4657066278912.0000\n",
            "Epoch 10/20\n",
            "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 156ms/step - accuracy: 0.8125 - loss: -8781185941504.0000 - val_accuracy: 0.7225 - val_loss: -4814528839680.0000\n",
            "Epoch 11/20\n",
            "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m452s\u001b[0m 2s/step - accuracy: 0.7297 - loss: -4758572630016.0000 - val_accuracy: 0.7188 - val_loss: -11297730068480.0000\n",
            "Epoch 12/20\n",
            "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 157ms/step - accuracy: 0.7812 - loss: -9296086564864.0000 - val_accuracy: 0.7221 - val_loss: -11217505615872.0000\n",
            "Epoch 13/20\n",
            "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m452s\u001b[0m 2s/step - accuracy: 0.7179 - loss: -9509699321856.0000 - val_accuracy: 0.7211 - val_loss: -22428956753920.0000\n",
            "Epoch 14/20\n",
            "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 157ms/step - accuracy: 0.7500 - loss: -16428998590464.0000 - val_accuracy: 0.7221 - val_loss: -22550939697152.0000\n",
            "Epoch 15/20\n",
            "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m502s\u001b[0m 2s/step - accuracy: 0.7262 - loss: -17795223912448.0000 - val_accuracy: 0.7211 - val_loss: -40157952606208.0000\n",
            "Epoch 16/20\n",
            "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 159ms/step - accuracy: 0.7188 - loss: -36262060752896.0000 - val_accuracy: 0.7225 - val_loss: -41536196706304.0000\n",
            "Epoch 17/20\n",
            "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m502s\u001b[0m 2s/step - accuracy: 0.7257 - loss: -30634091216896.0000 - val_accuracy: 0.7225 - val_loss: -64913124884480.0000\n",
            "Epoch 18/20\n",
            "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 159ms/step - accuracy: 0.7188 - loss: -114739027902464.0000 - val_accuracy: 0.7221 - val_loss: -65294366146560.0000\n",
            "Epoch 19/20\n",
            "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m502s\u001b[0m 2s/step - accuracy: 0.7235 - loss: -50924236046336.0000 - val_accuracy: 0.7235 - val_loss: -101009837785088.0000\n",
            "Epoch 20/20\n",
            "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 160ms/step - accuracy: 0.4688 - loss: -46832604413952.0000 - val_accuracy: 0.7225 - val_loss: -99059528368128.0000\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 653ms/step - accuracy: 0.7275 - loss: -98583172874240.0000\n",
            "Validation Accuracy: 72.19%\n"
          ]
        }
      ]
    }
  ]
}